# 개요
- AB180에서 디퍼드 딥링크 기능 제공 과정에서 최적화 작업 소개
- 개별 크기가 작은 대신 많은 데이터를 Redis에 효과적으로 저장하는 방법
- 하나의 모델을 두 서비스가 공유하는 방법

# 내용
## 발단
- 레디스에 데이터를 json 형태로 압축 없이 저장, 양이 매우 많음
- 하나의 레디스를 두 서비스에서 공유하지만, Json schema 없이 각자 모델 정의한 경우도  보였음
- 비용 절감을 목적으로 작업 시작   
<br>

## 예측 및 가설
- 데이터 특성 - nested object 형태, 한 레코드당 1KB 내외. 1시간 ttl 설정 했으나 데이터 양이 너무 많아 최대 1.1억개 이상 레코드가 저장되었음
- 직렬화 포맷 - Json 포맷 대신 압축 및 스키마 관리를 위해 Protobuf 사용
  - 한 서비스에서만 사용된다면 언어에 특화된 직렬화 포맷도 고려 가능
- 압축 알고리즘
  - 통계, 디버깅, 이슈 대응에 사용되는 데이터가 아니라 실 데이터이므로 저장 효율이 중요한 상황
- 벤치마크
  - 실제 저장되는 데이터를 수집하여 각 압축 알고리즘과 구현체를 비교
  - 같은 알고리즘에서도 구현체가 여러 개 있을 수 있는데, 언어와 성능(압축률, 수행 시간 등)을 따져 가며 여러 트레이드오프를 고려 가능. 압축 레벨, sliding window 등의 파라미터를 변화시켜 가며 적절한 레벨 선택
- Key 압축 수행
  - 16진수 문자열을 그대로 사용하는 것이 아닌, 기계가 읽을 수 있는 방식으로 압축하여 변환
- 레디스 내 저장 방식
  - 기존에는 String을 사용했으나, 다른 타입을 이용하여 사용량을 줄여 보는 실험 수행
    - protobuf 없이 hash 사용 - 레코드 전체가 필요했기 때문에 기능상 이점이 없었음
    - k-v를 유지하되 hash를 통한 샤딩 - 레코드마다 TTL이 붙어야 했기 때문에 불가능   
<br>

## 마이그레이션
- TTL이 존재하기 때문에 기존 데이터를 마이그레이션 할 필요는 없었음
- 데이터 포맷과 key가 완전히 달라졌기 때문에, 이로 인한 동작 변경이 없는지 검증이 필요
  - 오랜 기간동안 확인하면서 안전한지 검증 필요
    - 신규 클러스터를 생성
    - 기존 클러스터와 신규 클러스터에 모두 적재
    - 조회할 때 두 클러스터에서 모두 가져오도록 만들어서, 기능은 기존 클러스터 데이터를 기반으로 실행하고, 신규 클러스터 데이터는 기존 데이터와의 차이만 로깅
    - 차이가 없어지면, 기존 로직을 지우고 신규 클러스터에서만 조회하도록 변경
    - 이후 기존 클러스터 적재 로직을 삭제하고, 기존 클러스터 삭제   
<br>

## 스키마 공유 방법
- Protobuf에서는 다양한 언어의 코드를 생성해 주는 protoc가 있어서, 공유를 쉽게 할 수 있음
- 구글의 경우 하나의 protobuf repository를 만들고 모든 서비스가 한 repository를 바라보도록 구현되어 있음
- AB180에서는 한 서비스에서 패키징하여 다른 서비스에 제공하는 방식을 사용   
<br>

## 장애물
- 기술 부채
  - 다른 코드 베이스에서 개발되면서 서비스간 로직 차이가 있었음
  - 모델 필드 변경 시 한 서비스에서 변경 사항이 반영되지 않는 문제가 있었음
- IAM 기반 ACL
  - IAM 기반 인증을 이용하여 서비스 컨테이너의 aws 계정으로 인증을 진행했는데, Wrongpass로 접근에 실패하고, 많은 커넥션이 레디스에 쌓이며 조회가 느려지는 현상 발생
  - IAM 기반 인증 포기, 비밀번호 기반 인증 선택   
<br>

## 추가 최적화
- 불필요한 데이터 쌓지 않기
  - 상태 저장 방식을 바꿔서 메모리를 더 아끼는 방법도 있음. 해당 부분은 ab180의 구현 방식, 어느 상황에서나 불필요한 데이터를 최소화하는 방법에 대한 고민 필요
- TTL이 지난 레코드 더 자주 회수하기
  - 레디스는 TTL이 지난 레코드를 모두 실시간으로 지우지는 않음
  - expired_stale_perc를 보면 회수되지 않은 레코드의 비율을 볼 수 있는데, 주기를 짧게 할수도 있음
  - cpu 사용량 늘기 때문에 고려 필요
- Elasticache의 데이터 계층화 노드 사용하기
  - 속도가 느려도 된다면, 용량당 비용을 줄이는 방법으로 다른 노드를 사용할 수 있음


# 참고문헌
- https://engineering.ab180.co/stories/thanos-redis